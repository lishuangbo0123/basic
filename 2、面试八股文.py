# 包装工作经验使用、做到见多识广，不一定需要会，用过就行
'''
scrapy
    框架工作原理
    优点：内置了异步的数据下载（twisted）、高性能的持久化存储、高性能的数据解析及分布式

    scrapy-redis有什么优势

    因为redis是基于内存的数据库，所以他的查询与插入速度更快。
    分布式爬虫 可多台主机互相协作  爬取速度翻倍

                            调度器

    管道                      引擎           下载中间件           下载器

                            爬虫中间件

                            spider
布隆过滤器  -- 高级过滤器  先给每一个请求对象设置一个哈希指纹，先进性比对有的话就不爬了。没有再放入过滤器
spider：1.产生url并发送请求，2.进行数据解析
调度器：过滤器（去重请求对象）  将去重后的请求对象放在队列中。在队列中调度请求对象给引擎
下载器：下载 （异步下载内置twist模块）
引擎：数据流处理  触发事务
管道：持久化存储数据
为什么都要经过引擎。：1引擎可以触发事务，他知道什么时候干什么事。触发事务的原理是什么？通过数据流进行判断，如果接收到的是响应数据就知道该调用
爬虫文件里的解析方法。如果接收到的是item对象，就知道调用管道文件的process_item方法 如果是url就知道是爬虫文件给的要传给调度器 2.数据流处理，根据数据流进行判断，接收到
spider产生url,将请求对象发送给引擎，引擎再传给调度器，调度器中讲引擎对象用过滤器去重，然后放入到了队列中。调度器再将队列中的请求对象发送给引擎，
引擎传给下载器进行数据获取，下载器从互联网获取响应数据。下载器再将响应数据传给引擎，引擎再传给spider文件进行数据解析，将解析到的item传递给引擎，
引擎将item再传递给管道进行持久化存储


'''


'''
selenium、pyppeteer、playwright
    启动参数：什么启动参数可以解决什么样的问题
    等待：什么样的等待用在什么场景合适`
    内存：内存占用如何（成本计算）
'''

'''
用过那些抓包工具，具体说说
mac charles，windows 入门版fiddler。进阶版wireshark
fiddler  charles
基本上常用就是篡改请求参数，请求头啥的来进行快速的接口调试
'''

'''
异步爬虫框架用过哪些
    httpx：自己用着试试
    aiohttp   已尝试
        

'''
